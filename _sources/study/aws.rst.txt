
.. include:: /pentest_links.txt

.. _aws:

*******************
Amazon Web Services
*******************


AWS Documentation, Support, and Certification
=============================================


Documentation
-------------

See `AWS Documentation`_.


Support
-------

For no cost you can consult `AWS Discussion Forums`_. For paid support see `Getting Started with AWS Support`_.


Training & Certification
------------------------

See `Welcome to AWS Training and Certification`_ and `Prepare for AWS Certification`_. From `AWS Certification Frequently Asked Questions (FAQs)`_ :menuselection:`Schedule your exam --> Q: How much does an AWS Certification exam cost?`:

  The Cloud Practitioner exam is 100 USD. Associate-level exams are 150 USD. Professional-level and Specialty exams are 300 USD. Recertification exams are 75 USD.

And from :menuselection:`About AWS Certification --> Q: How long will my certification be valid?`:

  You will be required to update your certification (or “recertify”) every two years. View the `AWS Certification Recertification page <https://aws.amazon.com/certification/recertification/?src=certification-faqs>`_ for more details.

Another AWS (and more) training website is `A Cloud Guru <https://acloud.guru/membership>`_.


AWS background
==============


AWS Resource Names and IDs
--------------------------

See `Amazon Resource Names (ARNs) and AWS Service Namespaces`_ for ARN format and `Amazon Elastic Compute Cloud - Resource IDs`_ for resource id's (where the 8 character alphanumeric format has changed to 17 characters).


AWS Service Limits
------------------

See `AWS Service Limits`_.


AWS Security Credentials
------------------------

From `AWS Security Credentials`_, start with `AWS Account Root User Credentials vs. IAM User Credentials`_ and follow `IAM Best Practices`_. Also see `AWS Identity and Access Management Documentation`_. AWS 2FA (`SafeNet IDProve 100 6-digit OTP Token for Use with Amazon Web Services Only <https://www.amazon.com/SafeNet-IDProve-Time-based-6-Digit-Services/dp/B002CRN5X8>`_) is far behind Google which already supports U2F.


AWS Regions, Availability Zones, and Edge Locations
---------------------------------------------------

For this discussion, "instance" is an AWS virtual machine, "EBS" is a disk that can be used by an instance, and "AMI" is an Amazon Machine Image used to initialize an instance. More detail will be provided later.


See `AWS Global Infrastructure`_ for a list of AWS regions and their availability zones, along which are accessed via AWS Edge locations. Most regions have at least 3 availability zones (with the current exceptions of Osaka having 1 AZ and Canada Central region having 2 AZs).

Instances are created in an Availability Zone using `Amazon Elastic Compute Cloud Amazon Machine Images (AMI)`_:

  All AMIs are categorized as either backed by Amazon EBS, which means that the root device for an instance launched from the AMI is an Amazon EBS volume, or backed by instance store, which means that the root device for an instance launched from the AMI is an instance store volume created from a template stored in Amazon S3.


From `Amazon Elastic Compute Cloud Regions and Availability Zones`_:

  An Availability Zone is represented by a region code followed by a letter identifier; for example, us-east-1a. To ensure that resources are distributed across the Availability Zones for a region, we independently map Availability Zones to identifiers for each account. For example, your Availability Zone us-east-1a might not be the same location as us-east-1a for another account. There's no way for you to coordinate Availability Zones between accounts.

  When you launch an instance, you can optionally specify an Availability Zone in the region that you are using. If you do not specify an Availability Zone, we select one for you. When you launch your initial instances, we recommend that you accept the default Availability Zone, because this enables us to select the best Availability Zone for you based on system health and available capacity. If you launch additional instances, only specify an Availability Zone if your new instances must be close to, or separated from, your running instances.

Not all regions or AZs have the same capability: `AWS Regions and Endpoints`_ shows Amazon Translate endpoints only exist in 4 regions where Amazon VPC exist in many more.

Note that EBS storage is in an AZ, instances run in an AZ using EBS in that AZ, and use an AMI in the same region (not AZ).


AWS CLI
=======


Installing/configuring the AWS CLI
----------------------------------

See `AWS CLI - Configuring the AWS CLI`_. Installation and configuration can be as simple as:

.. code-block:: bash
  :emphasize-lines: 1,3,9-10

  pip install --upgrade awscli

  aws configure
  AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE
  AWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
  Default region name [None]: us-west-2
  Default output format [None]: ENTER

  aws configure list
  aws configure get region

However, when pentesting or switching between many different accounts it can be complex and error prone to keep you profiles straight. See `AWS CLI - Configuring the AWS CLI`_ *Configuration Settings and Precedence*, `AWS CLI - Environment Variables`_, and `AWS CLI - Configuration Variables`_ configuration details. To lessen the chance of using a wrong profile:

* Store projets in separate :envvar:`PROJECTDIR` directories, each containing their own AWS CLI profile files :file:`config` and :file:`credentials`.

  Use the environment variables :envvar:`AWS_CONFIG_FILE` and :envvar:`AWS_SHARED_CREDENTIALS_FILE` to redirect the profile files to the directory :envvar:`PROJECTDIR`. Make sure the files have are user-readable only (``chmod 600 ...``).

* No credentials in the default locations :file:`~/.aws/config` and :file:`~/.aws/credentials`.

* No ``[default]`` profile. Always specify ``aws --profile ...``.

* Unique profile names, so accidentally having the wrong :envvar:`AWS_CONFIG_FILE` or :envvar:`AWS_SHARED_CREDENTIALS_FILE` won't work.

An example setup is:

.. code-block:: bash
  :emphasize-lines: 1,4-8,15-21,24

  PROJECTDIR=$HOME/exploits/flaws
  rm -rf $PROJECTDIR && mkdir -p $PROJECTDIR && cd $PROJECTDIR

  # set up & switch new profile files - switch profile location for hacking
  export AWS_CONFIG_FILE=$PROJECTDIR/.config
  touch $AWS_CONFIG_FILE && chmod 600 $AWS_CONFIG_FILE
  export AWS_SHARED_CREDENTIALS_FILE=$PROJECTDIR/.credentials
  touch $AWS_SHARED_CREDENTIALS_FILE && chmod 600 $AWS_SHARED_CREDENTIALS_FILE

  AK='ASIA6GG7PSQG4ZN4VNFN'
  SAK='xz0hNfVmnsKIKNA74bHBl1BI2ls0b0mxmoUSQe/4'
  TOKEN='FQoGZXIvYXdzEAIaDL151RQGzmSqYQrr1iK3A/KX9ULZ1nzyhSj1s5WHKxI5t7uX07KggnDaJko0l2nd3Iqr7IhF8kC/YJAGdbyytbNXRtRObO6skLvBZMTWNVk4UfHhsdi53Wq92q2XLLkCQfYbNF1Q1bHrqhBVIb5SWqnTZt+I96UlNoyo+aYzTCIC+MmU4cWGOdS4hQhm9UlF3NahRhYip+MQwA/scoh9E/NBOL7l56pc9MmSeFAjUr06GMGG6+bRs7eGHoD9/rD0T+LQ8zEKGMc4PK6qDP+5VEMuyiF5lhZhnE0knjB7oxq0elt3fQ2tCFXu4ONKK80o8crrEPF6So3ht6m9N0NcJuIrcQQXA9Qw1XqbjJy5xImpGstAoZhUZaPCICNJJTHXVUCO7a/QkGcl217+f6rpt2GuLa5ePUveQMiwvmVTj8qepY6EXF7hm8Yqt6H+47n5XXod49hA94u2EeoO50wegjR8FrPVVj8Zrtn/Dh1SOsq8co0VI73eszBcX67nIo4rmtmfurXHZw+6Lm2pYDqq45dtHGknICE+aQKG7VEsw5/FCxn6BkbTSzS3N7HMzoiFdKWc2QSgg9nlCrwYSOJCEekecazA0vgo0NO42wU='
  REGION=us-west-2

  cat <<EOF | aws configure --profile $HACKER
  $AK
  $SAK
  $REGION
  json
  EOF
  aws --profile $HACKER configure set aws_session_token "$TOKEN"    

  # test profile
  aws --profile $HACKER iam get-user --output text --query 'User.Arn'


Regions and AZs
---------------

Here are some AWS CLI commands involving regions and AZ. (Note: see `How do I know what Ubuntu AMI to launch on EC2? <https://askubuntu.com/questions/53582/how-do-i-know-what-ubuntu-ami-to-launch-on-ec2#53586>`_.)

.. code-block:: bash
  :emphasize-lines: 1,7,17

  # Get complete region list, then current region and AZs
  aws ec2 describe-regions --output text  # or "table", "json"
  aws configure get region
  REGION=$(aws configure get region)
  aws ec2 describe-availability-zones

  # Get Ubuntu 18.04 LTS from Ubuntu for current region
  remove_last_comma() { sed '
          $x;$G;/\(.*\),/!H;//!{$!d
      };  $!x;$s//\1/;s/^\n//'
  }
  curl -s "https://cloud-images.ubuntu.com/locator/ec2/releasesTable" \
      | remove_last_comma \
      | jq -c '.aaData[] | select(contains(["18.04", "'$REGION'", "hvm:ebs"]))' \
      | grep -o 'ami-[a-z0-9]\+' | head -1

  # Get Ubuntu 18.04 LTS for current region from AWS
  aws --region "$REGION" ec2 describe-images --owners 099720109477 \
      --filters Name=root-device-type,Values=ebs \
                Name=architecture,Values=x86_64 \
		Name=name,Values='*hvm-ssd/ubuntu-bionic-18.04*' \
      --query 'Images[].[CreationDate,ImageId,Name]' --output text \
    | sort -k1 | tail -n1 | gawk '{print $2}'


SSH keys
--------

See `Amazon Elastic Compute Cloud Amazon EC2 Key Pairs <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html>`_ for options creating an SSH key pair. Note that SSH keys are stored in a region (using the current default region if not specified). If AWS creates the SSH key pair it returns the private key and keeps the public key. If you create your own SSH key pair you keep both and upload your public key - AWS never touches your private key.

.. code-block:: bash
  :emphasize-lines: 1,11,15,18

  # Generate SSH keypair
  EMAIL="bitbender@bitbender.org"
  KEYNAME=bitbender
  PRIVKEY="$HOME/.ssh/id_aws"
  PUBKEY="$PRIVKEY.pub"
  # NOTE - ed25519 doesn't work
  # ssh-keygen -a 50 -t ed25519 -C "$EMAIL" -f "$PRIVKEY"
  ssh-keygen -o -t rsa -C "$EMAIL" -f "$PRIVKEY"
  # password protect the key

  # Import into current region
  aws ec2 import-key-pair --key-name "$KEYNAME" \
      --public-key-material "file://$PUBKEY"

  # Verify keys uploaded
  aws ec2 describe-key-pairs

  # If need to delete the key
  aws ec2 delte-key-pair --key-name "$KEYNAME"


AWS CLI ``--query``
-------------------

`Controlling Command Output from the AWS Command Line Interface`_ describes using the ``--query`` option to simplify CLI access to AWS configuration/data. The format is based on JMESPath:

#. `JMESPath Specification <http://jmespath.org/specification.html>`_

   Note that literals are delimited by a back tick (`) and not the usual single quote (') or double quote (").

#. `JMESPath Tutorial <http://jmespath.org/tutorial.html>`_

#. `JMESPath Examples <http://jmespath.org/examples.html>`_

#. `AWS CLI JMESPath cheatsheet <https://gist.github.com/magnetikonline/6a382a4c4412bbb68e33e137b9a74168>`_

#. `THREE TIME-SAVING AWS COMMAND-LINE TRICKS <https://claudiajs.com/tutorials/aws-cli-tricks.html>`_ and `Using aws-cli --query Option To Simplify Output <https://alestic.com/2013/11/aws-cli-query/>`_ - short and simple articles

#. `JMESPath Query in the AWS CLI <https://opensourceconnections.com/blog/2015/07/27/advanced-aws-cli-jmespath-query/>`_ - more complex examples

There are 3 output choices: json (JSON), text (tab-delimited text), and table (ASCII-formatted table). In general, text is the best output choice:

  JSON is best for handling the output programmatically via various languages or jq (a command-line JSON processor). The table format is easy for humans to read, and text format works well with traditional Unix text processing tools, such as sed, grep, and awk, as well as Windows PowerShell scripts.

  *We strongly recommend that the text output be used along with the --query option to ensure consistent behavior.* This is because the text format alphabetically orders output columns, and similar resources may not always have the same collection of keys. For example, a JSON representation of a Linux EC2 instance may have elements that are not present in the JSON representation of a Windows instance, or vice versa. Also, resources may have key-value elements added or removed in future updates, altering the column ordering. This is where --query augments the functionality of the text output to enable complete control over the output format. In the example below, the command pre-selects which elements to display and defines the ordering of the columns with the list notation [key1, key2, ...]. This gives users full confidence that the correct key values will always be displayed in the expected column. Finally, notice how the AWS CLI outputs 'None' as values for keys that don't exist.

  .. code-block:: shell
    :emphasize-lines: 1-3
  
    $ aws ec2 describe-volumes \
        --query 'Volumes[*].[VolumeId, Attachments[0].InstanceId, AvailabilityZone, Size, FakeKey]' \
	--output text
    vol-e11a5288    i-a071c394      us-west-2a      30      None
    vol-2e410a47    i-4b41a37c      us-west-2a      8       None


Run EC2 instance
----------------

Here's an example of starting an EC2 instance using the AWS CLI:

.. code-block:: bash
  :emphasize-lines: 1,3,5,8,16,27,31,38,44,50,53,61

  # Info needed to create EC2 instance
  TYPE=t2.nano  # t2.nano t2.micro t2.small t2.medium
  # Region will default, but we'll set it here and let AWS choose AZ
  REGION=$(aws configure get region)
  # Use SSH key created previously
  KEYNAME="bitbender"
  PRIVKEY="$HOME/.ssh/id_aws"
  # Use Ubuntu 18.04 AMI
  AMI=$(aws --region "$REGION" ec2 describe-images --owners 099720109477 \
            --filters Name=root-device-type,Values=ebs \
                      Name=architecture,Values=x86_64 \
                      Name=name,Values='*hvm-ssd/ubuntu-bionic-18.04*' \
            --query 'Images[].[CreationDate,ImageId,Name]' --output text \
    | sort -k1 | tail -n1 | gawk '{print $2}'
  )
  # Create security group and get security group ID
  SG="PENTEST_MEETUP"
  SGID=$(aws ec2 create-security-group \
             --group-name "$SG" --description "Test Security Group" \
  )
  # sg-cbc2c5ba
  # Alternatively could query for security group ID
  SGID=$(aws ec2 describe-security-groups \
             --group-names "$SG" \
             --query 'SecurityGroups[*].{ID:GroupId}' \
  )
  # Allow SSH in security group
  aws ec2 authorize-security-group-ingress --group-id "$SGID" \
      --protocol tcp --port 22 --cidr 0.0.0.0/0 --region "$REGION"

  # Run the instance and tag it with name "pentest-meetup"
  VMNAME="pentest-meetup"
  aws ec2 run-instances --image-id "$AMI" --count 1 \
      --instance-type "$TYPE" --key-name "$KEYNAME" \
      --security-group-ids "$SGID" --region "$REGION" \
      --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value='$VMNAME'}]'

  # Get the instance ID
  INSTANCES=$(aws ec2 describe-instances \
                 --filters 'Name=tag:Name,Values=pentest-meetup' \
                 --query 'Reservations[*].Instances[*].InstanceId' \
                 --output text \
  )
  # Get the public DNS name
  PUBDNS=$(aws ec2 describe-instances \
             --filters 'Name=tag:Name,Values=pentest-meetup' \
             --query 'Reservations[*].Instances[*].PublicDnsName' \
             --output text \
  )
  # Wait for instance running
  aws ec2 wait instance-running --instance-ids "$INSTANCES"

  # Use the VM
  ssh -i "$PRIVKEY" ubuntu@$PUBDNS
  # See instance metadata and user data
  curl http://169.254.169.254/latest/meta-data/
  curl http://169.254.169.254/latest/user-data
  # ...
  exit

  # Terminate the VM and remove security group
  aws ec2 terminate-instances --instance-ids "$INSTANCES" --region "$REGION"
  aws ec2 delete-security-group --group-id "$SGID" --region "$REGION"

See `Amazon Elastic Compute Cloud Connecting to Your Linux Instance Using SSH <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AccessingInstancesLinux.html>`_ for SSH details.


Launch templates
----------------

From `Amazon Elastic Compute Cloud Launching an Instance from a Launch Template <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-launch-templates.html>`_:

  Launch templates enable you to store launch parameters so that you do not have to specify them every time you launch an instance. For example, a launch template can contain the AMI ID, instance type, and network settings that you typically use to launch instances. When you launch an instance using the Amazon EC2 console, an AWS SDK, or a command line tool, you can specify the launch template to use.

That document include an example of overriding the template:


.. code-block:: bash

  aws ec2 run-instances \
      --launch-template LaunchTemplateId=lt-0abcd290751193123 \
      --instance-type t2.small


AWS SDK
=======


AWS SDK for Python (Boto3)
--------------------------

The AWS SDK for Python is based on ``boto3``. See `Boto 3 Documentation`_ and the actual software `Boto 3 - The AWS SDK for Python`_. From `AWS SDK for Python (Boto3)`_:

  Boto3 has two distinct levels of APIs. Client (or "low-level") APIs provide one-to-one mappings to the underlying HTTP API operations. Resource APIs hide explicit network calls but instead provide resource objects and collections to access attributes and perform actions.

For the client APIs see `Boto 3 - User Guides - Low-level Clients`_, for the resource APIs see `Boto 3 - User Guides - Resources`_. Here goes the client interface to display key pairs based on `describe_key_pairs(**kwargs) <https://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.Client.describe_key_pairs>`_:

.. code-block:: python3
  :caption: get-keys-client.py
  :emphasize-lines: 18,21,26

  import sys
  import argparse
  import json
  import botocore
  import boto3

  parser = argparse.ArgumentParser()
  parser.add_argument("--profile", default = "default", help="optional AWS profile")
  parser.add_argument("--region", default = None, help="optional AWS region")
  args = parser.parse_args()

  try:
      session = boto3.session.Session(profile_name=args.profile)
  except botocore.exceptions.ProfileNotFound as err:
      print("--profile ERROR: {0}".format(err))
      exit(1)

  client = boto3.client('ec2',region_name=args.region)

  try:
      key_pairs = client.describe_key_pairs()
  except botocore.exceptions.EndpointConnectionError as err:
      print("--region ERROR: Region {0} - {1}".format(args.region,err))
      exit(2)

  sys.stdout.write(json.dumps(key_pairs,indent=2))
  EOF

Running ``python get-keys-client.py`` produces this rather detailed JSON output:

.. code-block:: json
  :emphasize-lines: 4-5,8-9

  {
    "KeyPairs": [
      {
	"KeyFingerprint": "11:22:33:44:55:66:77:88:99:aa:bb:cc:dd:ee:ff:00",
	"KeyName": "id_key1"
      },
      {
	"KeyFingerprint": "11:22:33:44:55:66:77:88:99:aa:bb:cc:dd:ee:ff:00:11:22:33:44",
	"KeyName": "id_key2"
      }
    ],
    "ResponseMetadata": {
      "RequestId": "aaaaaaaa-1111-2222-3333-123456789abc",
      "HTTPStatusCode": 200,
      "HTTPHeaders": {
	"content-type": "text/xml;charset=UTF-8",
	"content-length": "573",
	"date": "Wed, 15 Aug 2018 19:25:40 GMT",
	"server": "AmazonEC2"
      },
      "RetryAttempts": 0
    }
  }

For a resource, the documentation `class EC2.KeyPair(name) <https://boto3.readthedocs.io/en/latest/reference/services/ec2.html#keypair>`_ leads to:

.. code-block:: python3
  :caption: get-keys-resource.py
  :emphasize-lines: 18,21,26-

  import sys
  import argparse
  import json
  import botocore
  import boto3

  parser = argparse.ArgumentParser()
  parser.add_argument("--profile", default = "default", help="optional AWS profile")
  parser.add_argument("--region", default = None, help="optional AWS region")
  args = parser.parse_args()

  try:
      session = boto3.session.Session(profile_name=args.profile)
  except botocore.exceptions.ProfileNotFound as err:
      print("--profile ERROR: {0}".format(err))
      exit(1)

  resource = boto3.resource('ec2',region_name=args.region)

  try:
      key_pairs = resource.key_pairs.all()
  except botocore.exceptions.EndpointConnectionError as err:
      print("--region ERROR: Region {0} - {1}".format(args.region,err))
      exit(2)

  for k in key_pairs:
    print(k.name, k.key_fingerprint)

Running ``python3 get-keys-resource.py`` produces the output:

.. code-block:: text
  :emphasize-lines: 1-

  id_key1 11:22:33:44:55:66:77:88:99:aa:bb:cc:dd:ee:ff:00
  id_key2 11:22:33:44:55:66:77:88:99:aa:bb:cc:dd:ee:ff:00:11:22:33:44


.. _aws_iam:

AWS IAM
=======


IAM basics
----------

Background material:

#. `AWS IAM - What Is IAM?`_

   #. `AWS IAM - Understanding How IAM Works`_

   #. `AWS IAM - Overview of Access Management: Permissions and Policies`_

   #. `AWS Organizations - What Is AWS Organizations?`_

#. `AWS IAM - API Reference`_

   #. `AWS Security Credentials`_ and `AWS - Understanding and Getting Your Security Credentials`_

   #. `AWS IAM - IAM Best Practices`_

   #. `Signing AWS API Requests`_

Getting your AWS account ID and canonical user ID:

.. code-block:: bash
  :emphasize-lines: 1,4

  # AWS account ID
  aws iam get-user --output text --query 'User.Arn' | cut -d: -f5

  # AWS cacnonical user ID
  aws iam get-user --output text --query 'User.UserId'


Identities (Users, Groups, and Roles)
-------------------------------------

Study `AWS IAM - Identities (Users, Groups, and Roles)`_. The key points are:

Root User
  AWS account used to create your AWS account. Used for billing and one-time creation of IAM administrator user for further AWS account management.

IAM Users
  Your user accounts with varying permissions via policies. AWS has created `AWS IAM - AWS Managed Policies for Job Functions`_: AdministratorAccess, Billing, DatabaseAdministrator, DataScientist, PowerUserAccess, NetworkAdministrator, SystemAdministrator, SecurityAudit, SupportUser, and ViewOnlyAccess. These policies can be attached to roles (sometimes with restrictions on the role name prefix).

IAM Groups
  Collection of IAM users. "Note that a group is not truly an identity because it cannot be identified as a Principal in a `resource-based or trust policy <https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_identity-vs-resource.html>`_. It is only a way to attach policies to multiple users at one time."

IAM Roles
  A role is like an IAM user except "a role does not have any credentials (password or access keys) associated with it. Instead of being uniquely associated with one person, a role is intended to be assumable by anyone who needs it."

Temporary Credentials
  "Temporary credentials are primarily used with IAM roles" and "they expire automatically after a set period of time."



**When to Create an IAM User (Instead of a Role)**

* **You created an AWS account and you're the only person who works in your account.**

* **Other people in your group need to work in your AWS account, and your group is using no other identity mechanism.**

* **You want to use the** `command-line interface <http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html>`_ **(CLI) to work with AWS.**

**When to Create an IAM Role (Instead of a User)**

* **You're creating an application that runs on an Amazon Elastic Compute Cloud (Amazon EC2) instance and that application makes requests to AWS.**

  For details, see `Using an IAM Role to Grant Permissions to Applications Running on Amazon EC2 Instances <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2.html>`_.

* **You're creating an app that runs on a mobile phone and that makes requests to AWS.**

* **Users in your company are authenticated in your corporate network and want to be able to use AWS without having to sign in again—that is, you want to allow users to federate into AWS.**


Policies
--------

Study `AWS IAM - Policies and Permissions`_, which states: "You manage access in AWS by creating policies and attaching them to IAM identities or AWS resources." The types of policies are: identity-based, resource-based, organization SCP (service control policy), and ACLs (access control lists). The purpose of policies is to act as a permissions policy (permissions for an object) or as a permissions boundary (maximum permissions a principal can have). The permissions policies are one of: identity-based, resource-based, or ACLs. The permissions boundaries are a SCP or and indentity-based policy applied to an IAM user or role.


Identity-based policies
^^^^^^^^^^^^^^^^^^^^^^^

Identity-based policies are JSON permissions policies attached to a principal (IAM user, role, or group) to control actions on resources. The policies are either managed or inline.

Managed policies
  "Standalone identity-based policies that you can attach to multiple users, groups, and roles in your AWS account. You can use two types of managed policies:"

  AWS managed policies
    "Managed policies that are created and managed by AWS."

  Customer managed policies
    "Managed policies that you create and manage in your AWS account."

Inline policies
  "Policies that you create and manage and that are embedded directly into a single user, group, or role."

From `AWS IAM - Managed Policies and Inline Policies`_, "Managed policies provide the following features: Reusability ... Central change management ... Versioning and rolling back ... Delegating permissions management ... Automatic updates for AWS managed policies". In contrast, "Inline policies are useful if you want to maintain a strict one-to-one relationship between a policy and the principal entity that it's applied to."


Resource-based policies
^^^^^^^^^^^^^^^^^^^^^^^

Resource-based policies are inline (not managed) JSON policy documents attached to a resource. "Remember that adding a principal to a resource-based policy is only half of establishing the trust relationship. You must also use an identity-based policy to grant the principal access to the resource."

At create time a role must have two resource-based policies attached: a **trust policy** (which principals can assume the role) and a **permissions policy** (what can be done with the role).


Service control policies
^^^^^^^^^^^^^^^^^^^^^^^^

"AWS Organizations is a service for grouping centrally managing the AWS accounts that your business owns." You can define OUs (Organizational Units) and can apply SCPs to organization or OUs. "This permissions boundary controls the maximum services and actions that can be accessed by the entities in those accounts."


Access control policies
^^^^^^^^^^^^^^^^^^^^^^^

ACLs are a legacy permission that "allow you to control what principals can access a resource. ACLs are similar to resource-based policies, although they are the only policy type that does not use the JSON policy document format. These policies use XML as opposed to the JSON for all other policies.


Policy examples
^^^^^^^^^^^^^^^

See `AWS IAM - Example Policies`_.


JSON for policies
^^^^^^^^^^^^^^^^^

To deal with JSON see `AWS IAM - Creating IAM Policies`_ and `AWS IAM - Editing IAM Policies`_. By far the easiest way to manipulate the JSON text is the management console's visual editor. It provides context-sensitive help, like a list of policies and the possible values for actions, conditions, ... .


AWS CLI from user to policies
-----------------------------

Here is the AWS CLI to determine the permissions for an admin user:

.. code-block:: bash
  :emphasize-lines: 1,5,10,14,20

  # Pick an admin user
  aws iam list-users
  IU=$(aws iam list-users --output text --query 'Users[0].UserName')

  # List groups for user
  aws iam list-groups-for-user --user-name $IU
  IG=$(aws iam list-groups-for-user --user-name $IU \
         --output text --query 'Groups[0].GroupName')

  # List policies attached to user
  aws iam list-attached-user-policies --user-name $IU
  # no attached policies for user

  # List policies attached to group
  aws iam list-attached-group-policies --group-name $IG
  # only 1 attached policy
  POL=$(aws iam list-attached-group-policies --group-name $IG \
            --output text --query 'AttachedPolicies[0].PolicyArn')

  # Investigate the policy
  aws iam list-entities-for-policy --policy-arn $POL # who else has the policy?
  aws iam get-policy --policy-arn $POL  # shows default version
  aws iam list-policy-versions --policy-arn $POL  # see if other versions (no)
  VER=$(aws iam list-policy-versions --policy-arn $POL \
          --output text --query 'Versions[0].VersionId')
  aws iam get-policy-version --policy-arn $POL --version-id $VER


AWS S3
======


S3 basics
---------

Background material:

#. `Amazon S3 Frequently Asked Questions`_

#. `Amazon S3 - Introduction to Amazon S3`_

#. `Amazon S3 REST API Introduction`_

#. `Amazon S3 - Working with Amazon S3 Buckets`_

#. `Amazon S3 - Making Requests`_

#. `Amazon S3 - Managing Access Permissions to Your Amazon S3 Resources`_

#. `IAM Policies and Bucket Policies and ACLs! Oh, My! (Controlling Access to S3 Resources)`_

     As a general rule, AWS recommends using S3 bucket policies or IAM policies for access control. S3 ACLs is a legacy access control mechanism that predates IAM.

#. `Amazon S3 - Guidelines for Using the Available Access Policy Options`_

#. `Amazon S3 - Access Control List (ACL) Overview`_ - Authenticated/All Users groups are source of misconfiguration

      A grantee can be an AWS account or one of the predefined Amazon S3 groups.

      Amazon S3 has a set of predefined groups. ...

        **Authenticated Users group** ... represents all AWS accounts. Access permission to this group allows any AWS account to access the resource. However, all requests must be signed (authenticated).

        **All Users group** ... Access permission to this group allows anyone in the world access to the resource. The requests can be signed (authenticated) or unsigned (anonymous).

        **Log Delivery group** ... WRITE permission on a bucket enables this group to write server access logs ... to the bucket.


Security and making S3 requests
-------------------------------


Making requests
^^^^^^^^^^^^^^^

From `Amazon S3 - Making Requests`_:

* Amazon S3 is a REST service.

* Every interaction with Amazon S3 is either authenticated or anonymous.

  Authenticated requests must include a signature value that authenticates the request sender. The signature value is, in part, generated from the requester's AWS access keys (access key ID and secret access key).

* Access key types - access key ID (20-character), secret access key (40-character)

  * AWS Account Access Keys - for root account.

  * IAM User Access Keys

  * Temporary Security Credentials - IAM temporary credentials adding a security token in addition to access key ID and secret access key.

* REST requests are sent to S3's predefined endpoints. See `AWS Regions and Endpoints`_ section for Amazon Simple Storage Service (Amazon S3).

  Region us-east-1 is special and is accessed via s3.amazonaws.com along with {s3.us-east-1,s3-external-1.amazonaws.com,s3.dualstack.us-east-1}.amazonaws.com (where dualstack is IPv4 + IPv6). Most, but not all, other regions are similar but without s3.amazonaws.com (and the region changed, too).

  When a bucket is configured as a website they used the website endpoint s3-website.us-east-1.amazonaws.com for us-east-1 and similarly for other regions.

From `Amazon S3 - Making Requests Using the REST API`_ the REST API can use *virtual hosted-style* or *path-style* URIs:

* Virtual Hosted-Style Request

  .. code-block:: http
    :emphasize-lines: 1-2,5

    DELETE /puppy.jpg HTTP/1.1
    Host: examplebucket.s3-us-west-2.amazonaws.com
    Date: Mon, 11 Apr 2016 12:00:00 GMT
    x-amz-date: Mon, 11 Apr 2016 12:00:00 GMT
    Authorization: authorization string

* Path-Style Request (requires region-specific endpoint)

  .. code-block:: http
    :emphasize-lines: 1-2,5

    DELETE /examplebucket/puppy.jpg HTTP/1.1
    Host: s3-us-west-2.amazonaws.com
    Date: Mon, 11 Apr 2016 12:00:00 GMT
    x-amz-date: Mon, 11 Apr 2016 12:00:00 GMT
    Authorization: authorization string

See `Amazon S3 - Virtual Hosting of Buckets`_ for details of using REST via virtual hosting. Virtual hosting offers the advantages of a customized URL (bucket name for host part of URL) and publishing the "root directory" of the bucket's virtual server.

"When using virtual hosted-style buckets with SSL, the SSL wild card certificate only matches buckets that do not contain periods." This prevents using a CNAME alias like https://www.example.com/ forcing an ugly url https://www.example.com.s3-us-west-2.amazonaws.com for HTTPS.


Unauthenticated and authenticated S3 access
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To access S3 without signing the request use the ``aws --no-sign-request ...`` option:

.. code-block:: bash
  :emphasize-lines: 1-2,6-7

  aws help
  # --no-sign-request (boolean)
  #   Do not sign requests. Credentials will not be loaded if this argument
  #   is provided.

  aws --no-sign-request --region us-west-2 \
    s3 ls s3://flaws.cloud/

To create an account to use in hacking S3 buckets follow `AWS IAM - Creating an IAM User in Your AWS Account`_:

.. code-block:: bash
  :emphasize-lines: 7,10,13,16,19,25,29

  # Px = pentest User, Group, passWord
  PU=hacker
  PG=Administrators
  PW='PleaseChangeMeS00n!'

  # create user
  aws iam create-user --user-name $PU

  # access to the AWS Management Console
  aws iam create-login-profile --user $PU --password $PW --password-reset-required

  # programmatic access
  aws iam create-access-key --user-name $PU --output json

  # add user to group
  aws iam add-user-to-group --user-name $PU --group-name $PG

  # set up profile
  aws configure --profile $PU
  # Access Key ID
  # Secret Access Key
  # Default region us-west-2
  # Default output format json

  # test profile
  aws s3 ls s3://level2-c8b217a33fcf1f839f6f1f73a00a9ae7.flaws.cloud \
    --profile $PU

  # when done delete user
  aws iam delete-login-profile --user-name $PU
  GS=$(aws iam list-groups-for-user --user-name $PU --output text \
    --query 'Groups[].GroupName')
  for G in $GS; do
    aws iam remove-user-from-group --group-name $G  --user-name $PU
  done
  KS=$(aws iam list-access-keys --user-name $PU --output text \
    --query 'AccessKeyMetadata[].AccessKeyId')
  for K in $KS; do
    aws iam delete-access-key --user-name $PU --access-key-id $K
  done
  aws iam delete-user --user-name $PU


Static website hosting on S3
----------------------------

See `Projects on AWS: Hosting a Static Website`_ for an overview of using CloudFront backed by S3. Follow `AWS S3 - Example: Setting up a Static Website Using a Custom Domain`_ to set up an HTTP (not HTTPS) website using S3 only. Then `AWS S3 - Example: Speed Up Your Website with Amazon CloudFront`_. CloudFront configuration modifies bucket policy to allow CloudFront access to the bucket:

.. code-block:: bash
  :emphasize-lines: 2,11,14

  WS=marengosystems.org
  aws s3api get-bucket-policy --bucket $WS --profile marengo | jq '.'
  # {
  #   "Version": "2008-10-17",
  #   "Id": "PolicyForCloudFrontPrivateContent",
  #   "Statement": [
  #     {
  #       "Sid": "1",
  #       "Effect": "Allow",
  #       "Principal": {
  #         "AWS": "arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity E123456789ABCD"
  #       },
  #       "Action": "s3:GetObject",
  #       "Resource": "arn:aws:s3:::example.com/*"
  #     }
  #   ]
  # }

From `AWS S3 - Website Endpoints`_ the S3 bucket endpoint can be one of the following 2 depending on the region:

.. code-block:: html
  :emphasize-lines: 1-

  bucket-name.s3-website-region.amazonaws.com
  bucket-name.s3-website.region.amazonaws.com

See `AWS S3 - Key Differences Between the Amazon Website and the REST API Endpoint`_ which shows the website endpoint supports only publicly readable content and doesn't support SSL connections.











												 













AWS VPC
=======


AWS VPC documentation
---------------------

See `AWS Documentation`_ for the complete documentation collection and `Amazon Virtual Private Cloud Documentation`_ for VPC documentation.


EC2-Classic vs EC2-VPC
----------------------

`Amazon Elastic Compute Cloud - Supported Platforms`_ allows instances to be launched into:

* EC2-Classic - original EC2 release where instances for all cusomters run in a single, flat network.

* EC2-VPC - instances run in a VPC (virutal private cloud) logically isolated to your AWS account.

See `Differences Between EC2-Classic and EC2-VPC`_.

To see if your AWS account supports only VPC:

.. code-block:: bash

  aws ec2 describe-account-attributes
  aws ec2 describe-account-attributes --attribute-names supported-platforms


VPCs and Subnets
----------------

See `Amazon Virtual Private Cloud - What Is Amazon VPC?`_ for an introduction. Each VPC must have at least 1 IPv4 CIDR block and an optional IPv6 /56 block. The subnets within the VPC are allocated non-overlapping CIDR blocks from within the VPC CIDR blocks, with IPv6 having /64 subnets. A VPC is contained in a region and each subnet is within one availability zone. Each AWS account has a default VPC with a default subnet in each AZ and an Internet gateway. EC2 instances are launched into the default VPC unless specified otherwise.

See `Amazon Virtual Private Cloud - VPCs and Subnets`_ for a discussion of these terms: route table; VPGW (VPN connection with Virtual private gateway and customer gateway endpoints); IGW (Internet Gateway); NAT; EIGW (IPv6 egress gateway); AWS PrivateLink; security group; network ACL; flow log. See `Amazon Virtual Private Cloud - Egress-Only Internet Gateways`_ for more information on EIGW.

The primary CIDR for a VPC has the first 4 and last address reserved (+0 = subnet, +1 = router, +2 = DNS, +3 = reserved for future use, -0 = reserved), which are also reserved for each subnet.

The AWS CLI can be used to display the default VPC and subnets:

.. code-block:: bash
  :emphasize-lines: 1,22,49

  aws ec2 describe-vpcs --filters 'Name=isDefault,Values=true' --output table
  #  ---------------------------------------------------------------------------------------------------
  #  |                                          DescribeVpcs                                           |
  #  +-------------------------------------------------------------------------------------------------+
  #  ||                                             Vpcs                                              ||
  #  |+---------------+----------------+------------------+------------+-------------+----------------+|
  #  ||   CidrBlock   | DhcpOptionsId  | InstanceTenancy  | IsDefault  |    State    |     VpcId      ||
  #  |+---------------+----------------+------------------+------------+-------------+----------------+|
  #  ||  172.31.0.0/16|  dopt-11111111 |  default         |  True      |  available  |  vpc-11111111  ||
  #  |+---------------+----------------+------------------+------------+-------------+----------------+|
  #  |||                                   CidrBlockAssociationSet                                   |||
  #  ||+--------------------------------------------------------+------------------------------------+||
  #  |||                      AssociationId                     |             CidrBlock              |||
  #  ||+--------------------------------------------------------+------------------------------------+||
  #  |||  vpc-cidr-assoc-11111111                               |  172.31.0.0/16                     |||
  #  ||+--------------------------------------------------------+------------------------------------+||
  #  ||||                                      CidrBlockState                                       ||||
  #  |||+----------------------------------+--------------------------------------------------------+|||
  #  ||||  State                           |  associated                                            ||||
  #  |||+----------------------------------+--------------------------------------------------------+|||

  aws ec2 describe-vpcs --filters 'Name=isDefault,Values=true' --output json
  #  {
  #      "Vpcs": [
  #          {
  #              "CidrBlock": "172.31.0.0/16",
  #              "DhcpOptionsId": "dopt-11111111",
  #              "State": "available",
  #              "VpcId": "vpc-11111111",
  #              "InstanceTenancy": "default",
  #              "CidrBlockAssociationSet": [
  #                  {
  #                      "AssociationId": "vpc-cidr-assoc-11111111",
  #                      "CidrBlock": "172.31.0.0/16",
  #                      "CidrBlockState": {
  #                      "State": "associated"
  #                      }
  #                  }
  #              ],
  #              "IsDefault": true
  #          }
  #      ]
  #  }

  DHCPID=$(aws ec2 describe-vpcs \
    --filters 'Name=isDefault,Values=true' --output text \
    --query 'Vpcs[].DhcpOptionsId')

  aws ec2 describe-dhcp-options --dhcp-options-id $DHCPID --output json
  #  {
  #      "DhcpOptions": [
  #          {
  #              "DhcpConfigurations": [
  #                  {
  #                      "Key": "domain-name",
  #                      "Values": [
  #                          {
  #                              "Value": "us-west-2.compute.internal"
  #                          }
  #                      ]
  #                  },
  #                  {
  #                      "Key": "domain-name-servers",
  #                      "Values": [
  #                          {
  #                              "Value": "AmazonProvidedDNS"
  #                          }
  #                      ]
  #                  }
  #              ],
  #              "DhcpOptionsId": "dopt-11111111"
  #          }
  #      ]
  #  }


Subnet security
---------------

See `Amazon Virtual Private Cloud - Security`_ for a more detailed discussion of security groups, network ACLs, and Flow logs. More details are available at `Amazon Virtual Private Cloud - Security Groups for Your VPC`_, `Amazon Virtual Private Cloud - Network ACLs`_, `Amazon Virtual Private Cloud - VPC Flow Logs`_.

.. code-block:: bash
  :emphasize-lines: 5-7

  VPCID=$(aws ec2 describe-vpcs \
    --filters 'Name=isDefault,Values=true' --output text \
    --query 'Vpcs[].VpcId')

  aws ec2 describe-subnets \
    --filters 'Name=defaultForAz,Values=true' "Name=vpcId,Values=$VPCID" \
    --output json
  #  {
  #      "Subnets": [
  #          {
  #              "AvailabilityZone": "us-west-2c",
  #              "AvailableIpAddressCount": 4091,
  #              "CidrBlock": "172.31.0.0/20",
  #              "DefaultForAz": true,
  #              "MapPublicIpOnLaunch": true,
  #              "State": "available",
  #              "SubnetId": "subnet-33333333",
  #              "VpcId": "vpc-11111111",
  #              "AssignIpv6AddressOnCreation": false,
  #              "Ipv6CidrBlockAssociationSet": []
  #          },
  #          {
  #              "AvailabilityZone": "us-west-2b",
  #              "AvailableIpAddressCount": 4091,
  #              "CidrBlock": "172.31.16.0/20",
  #              "DefaultForAz": true,
  #              "MapPublicIpOnLaunch": true,
  #              "State": "available",
  #              "SubnetId": "subnet-22222222",
  #              "VpcId": "vpc-11111111",
  #              "AssignIpv6AddressOnCreation": false,
  #              "Ipv6CidrBlockAssociationSet": []
  #          },
  #          {
  #              "AvailabilityZone": "us-west-2a",
  #              "AvailableIpAddressCount": 4091,
  #              "CidrBlock": "172.31.32.0/20",
  #              "DefaultForAz": true,
  #              "MapPublicIpOnLaunch": true,
  #              "State": "available",
  #              "SubnetId": "subnet-11111111",
  #              "VpcId": "vpc-11111111",
  #              "AssignIpv6AddressOnCreation": false,
  #              "Ipv6CidrBlockAssociationSet": []
  #          }
  #      ]
  #  }

Next we look at the default security group for the VPC, having inbound rule allowing all IPv4 traffic from instances in the same security group and outbound rule allowing all outbound IPv4 traffic (0.0.0.0/0):

.. code-block:: bash
  :emphasize-lines: 6,20,33

  SGID=$(aws ec2 describe-security-groups \
    --filters 'Name=group-name,Values=default' "Name=vpc-id,Values=$VPCID" \
    --output text \
    --query 'SecurityGroups[].GroupId')
 
  aws ec2 describe-security-groups --group-ids "$SGID" --output json
  #  {
  #      "SecurityGroups": [
  #          {
  #              "Description": "default VPC security group",
  #              "GroupName": "default",
  #              "IpPermissions": [
  #                  {
  #                      "IpProtocol": "-1",
  #                      "IpRanges": [],
  #                      "Ipv6Ranges": [],
  #                      "PrefixListIds": [],
  #                      "UserIdGroupPairs": [
  #                          {
  #                              "GroupId": "sg-11111111",
  #                              "UserId": "111111111111"
  #                          }
  #                      ]
  #                  }
  #              ],
  #              "OwnerId": "111111111111",
  #              "GroupId": "sg-11111111",
  #              "IpPermissionsEgress": [
  #                  {
  #                      "IpProtocol": "-1",
  #                      "IpRanges": [
  #                          {
  #                              "CidrIp": "0.0.0.0/0"
  #                          }
  #                      ],
  #                      "Ipv6Ranges": [],
  #                      "PrefixListIds": [],
  #                      "UserIdGroupPairs": []
  #                  }
  #              ],
  #              "VpcId": "vpc-11111111"
  #          }
  #      ]
  #  }

Next review the route tables for the VPC which show there's an IGW:

.. code-block:: bash
  :emphasize-lines: 1-3,25,40

  aws ec2 describe-route-tables \
    --filters "Name=vpc-id,Values=$VPCID" \
    --output json
  #  {
  #      "RouteTables": [
  #          {
  #              "Associations": [
  #                  {
  #                      "Main": true,
  #                      "RouteTableAssociationId": "rtbassoc-11111111",
  #                      "RouteTableId": "rtb-11111111"
  #                  }
  #              ],
  #              "PropagatingVgws": [],
  #              "RouteTableId": "rtb-11111111",
  #              "Routes": [
  #                  {
  #                      "DestinationCidrBlock": "172.31.0.0/16",
  #                      "GatewayId": "local",
  #                      "Origin": "CreateRouteTable",
  #                      "State": "active"
  #                  },
  #                  {
  #                      "DestinationCidrBlock": "0.0.0.0/0",
  #                      "GatewayId": "igw-11111111",
  #                      "Origin": "CreateRoute",
  #                      "State": "active"
  #                  }
  #              ],
  #              "Tags": [],
  #              "VpcId": "vpc-11111111"
  #          }
  #      ]
  #  }

  IGW=$(aws ec2 describe-route-tables \
    --filters "Name=vpc-id,Values=$VPCID" --output text \
    --query 'RouteTables[*].Routes[?starts_with(GatewayId,`igw`)].GatewayId')

  aws ec2 describe-internet-gateways --internet-gateway-ids "$IGW" --output json
  #  {
  #      "InternetGateways": [
  #          {
  #              "Attachments": [
  #                  {
  #                      "State": "available",
  #                      "VpcId": "vpc-11111111"
  #                  }
  #              ],
  #              "InternetGatewayId": "igw-11111111",
  #              "Tags": []
  #          }
  #      ]
  #  }

Finally display the network acls allowing all outbound and inbound traffic:

.. code-block:: bash
  :emphasize-lines: 1-3

  aws ec2 describe-network-acls \
    --filters 'Name=default,Values=true' "Name=vpc-id,Values=$VPCID" \
    --output json
  #  {
  #      "NetworkAcls": [
  #          {
  #              "Associations": [
  #                  {
  #                      "NetworkAclAssociationId": "aclassoc-33333333",
  #                      "NetworkAclId": "acl-33333333",
  #                      "SubnetId": "subnet-33333333"
  #                  },
  #                  {
  #                      "NetworkAclAssociationId": "aclassoc-22222222",
  #                      "NetworkAclId": "acl-22222222",
  #                      "SubnetId": "subnet-22222222"
  #                  },
  #                  {
  #                      "NetworkAclAssociationId": "aclassoc-11111111",
  #                      "NetworkAclId": "acl-22222222",
  #                      "SubnetId": "subnet-11111111"
  #                  }
  #              ],
  #              "Entries": [
  #                  {
  #                      "CidrBlock": "0.0.0.0/0",
  #                      "Egress": true,
  #                      "Protocol": "-1",
  #                      "RuleAction": "allow",
  #                      "RuleNumber": 100
  #                  },
  #                  {
  #                      "CidrBlock": "0.0.0.0/0",
  #                      "Egress": true,
  #                      "Protocol": "-1",
  #                      "RuleAction": "deny",
  #                      "RuleNumber": 32767
  #                  },
  #                  {
  #                      "CidrBlock": "0.0.0.0/0",
  #                      "Egress": false,
  #                      "Protocol": "-1",
  #                      "RuleAction": "allow",
  #                      "RuleNumber": 100
  #                  },
  #                  {
  #                      "CidrBlock": "0.0.0.0/0",
  #                      "Egress": false,
  #                      "Protocol": "-1",
  #                      "RuleAction": "deny",
  #                      "RuleNumber": 32767
  #                  }
  #              ],
  #              "IsDefault": true,
  #              "NetworkAclId": "acl-11111111",
  #              "Tags": [],
  #              "VpcId": "vpc-11111111"
  #          }
  #      ]
  #  }


VPC Peering
-----------

VPC peering allows network traffic to travel between VPCs of the same or different AWS account VPCs via private IPv4 or IPv6 addresses, even between different regions. Start with `Amazon Virtual Private Cloud - What is VPC Peering?`_ and `Amazon Virtual Private Cloud - VPC Peering Basics`_. The major restrictions are detailed in `Amazon Virtual Private Cloud - Unsupported VPC Peering Configurations`_:

* No overlapping CIDR blocks.

* No IPv6 for inter-region VPC peering connection.

* VPC peering is not transitive, so anything connected to a VPC is not accessible to its peer:

  * A transivitve (remote) VPC requires direct peering.

  * VPN

  * Internet gateway

  * NAT device

  * AWS service VPC endpoint

For assistance with customer gateway VPN setup see `Amazon Virtual Private Cloud - Network Administrator Guide`_.


AWS EC2 instances
=================


On-demand, spot, reserved, and dedicated instances
--------------------------------------------------

On-demand
  Normal EC2 instance available on demand.

Spot instance
  Spare compute capacity available at steep discounts. See `Amazon EC2 Spot Instances <https://aws.amazon.com/ec2/spot/>`_. "The only difference between On-Demand instances and Spot Instances is that Spot instances can be interrupted by EC2 with two minutes of notification when EC2 needs the capacity back." See `Interruption Behavior <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-interruptions.html#interruption-behavior>`_ for interruption options.

Reserved instance
  Get discount by committing to 1 or 3 years instance usage. See `Amazon EC2 Reserved Instances <https://aws.amazon.com/ec2/pricing/reserved-instances/>`_. Standard RIs are for steady state usage; convertible RIs are like standard RIs except they can be upgraded to instances of equal or greater value; and scheduled RIs which have "a predictable recurring schedule that only requires a fraction of a day, a week, or a month."

Dedicated instances
  Hardware is dedicated to a single customer. See `Amazon EC2 Dedicated Instances <https://aws.amazon.com/ec2/purchasing-options/dedicated-instances/>`_ and `Amazon EC2 Dedicated Hosts <https://aws.amazon.com/ec2/dedicated-hosts/>`_.


Instance types
--------------


Instance families
^^^^^^^^^^^^^^^^^

`Amazon Elastic Compute Cloud Instance Types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html>`_ lists these families: general purpose, compute optimized, memory optimized, storage optimized, and accelerated computing. Also see `Amazon EC2 Instance Types <https://aws.amazon.com/ec2/instance-types/>`_.


Virtualization types
^^^^^^^^^^^^^^^^^^^^

From `Amazon Elastic Compute Cloud Instance Types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html>`_, there are HVM (hardware virtual machine) and PV (paravirtual) instances:

  For best performance, we recommend that you use an HVM AMI. In addition, HVM AMIs are required to take advantage of enhanced networking. HVM virtualization uses hardware-assist technology provided by the AWS platform. With HVM virtualization, the guest VM runs as if it were on a native hardware platform, except that it still uses PV network and storage drivers for improved performance.

From `Amazon Elastic Compute Cloud - Linux AMI Virutalization Types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/virtualization_types.html>`_:

  Paravirtual guests traditionally performed better with storage and network operations than HVM guests because they could leverage special drivers for I/O that avoided the overhead of emulating network and disk hardware, whereas HVM guests had to translate these instructions to emulated hardware. Now PV drivers are available for HVM guests, so operating systems that cannot be ported to run in a paravirtualized environment can still see performance advantages in storage and network I/O by using them. With these PV on HVM drivers, HVM guests can get the same, or better, performance than paravirtual guests.


Networking
^^^^^^^^^^

Networking between instances can be optimized by `Amazon Elastic Compute Cloud Placement Groups <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html>`_:

Cluster
  Clusters instances into a low-latency group in a single Availability Zone.

Spread
  Spreads instances across underlying hardware. They can span Availability Zones.

Note that `Amazon Elastic Compute Cloud Enhanced Networking on Linux <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html>`_ providing 10 or 25 Gbps network speeds is supported on selected instance types.


Storage
^^^^^^^

See the figure at `Amazon Elastic Compute Cloud Storage <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Storage.html>`_  for the different types of storage.

Instance Store
  Disks physically attached to host computer, with data lost when instance is stopped or terminated. See `Amazon Elastic Compute Cloud Amazon EC2 Instance Store <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html>`_.

EBS
  A raw, unformatted external block device that can be attached to a single instance, persisting independently from the instance. EBS volumes can be created as encrypted volumes. See `Amazon Elastic Compute Cloud Amazon Elastic Block Store (Amazon EBS) <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html>`_. Can create:

  General Purpose SSD
    3 IOPS/GiB with burst to 3,000 IOPS. These "volumes support up to 10,000 IOPS and 160 MB/s throughput".

  Provisioned IOPS
    These "support up to 32,000 IOPS and 500 MB/s throughput".

  Throughput Optimized HDD
    Optimized HDD provides "low-cost magnetic storage that defines performance in terms of throughput rather than IOPS. With throughput of up to 500 MiB/s."

  Cold HDD
    Magnetic storage up to 250 MiB/s.

  These can be encrypted, can create point-in-time snapshot, are create in an Availability Zone for instances in the same Availability Zone. They can be initialized with public data sets (see `Amazon Elastic Compute Cloud Using Public Data Sets <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-public-data-sets.html>`_).

EFS
  NFS storage. See `Amazon Elastic Compute Cloud Amazon Elastic File System (Amazon EFS) <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEFS.html>`_.

S3
  Reliable and inexpensive storage, including snapshots and AMIs.


Root device
^^^^^^^^^^^

All AMIs are either backed by EBS or instance store. See `Amazon Elastic Compute Cloud AMI Types - Storage for the Root Device <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ComponentsAMIs.html#storage-for-the-root-device>`_. Note that all of the lesser cost T2 instances must use EBS for instance storage. Also see `AWS OpsWorks Best Practices: Root Device Storage for Instances <https://docs.aws.amazon.com/opsworks/latest/userguide/best-practices-storage.html>`_: EBS instances restart faster, EBS-backed instances pay for the EBS volume even when the instance is not running, and logs on EBS-backed instance persist with the volume.


Bursting
^^^^^^^^

CPU bursting
""""""""""""

From `Burstable Performance Instances <https://aws.amazon.com/ec2/instance-types/#burst>`_
`Burstable Performance Instances <https://aws.amazon.com/ec2/instance-types/#burst>`_:

  Amazon EC2 allows you to choose between Fixed Performance Instances (e.g. M3, C3, and R3) and Burstable Performance Instances (e.g. T2). Burstable Performance Instances provide a baseline level of CPU performance with the ability to burst above the baseline.

  The hourly T2 instance price automatically covers all interim spikes in usage when the average CPU utilization of a T2 instance is at or less than the baseline over a 24-hour window. If the instance needs to run at higher CPU utilization for a prolonged period, it can do so at a flat additional charge of 5 cents per vCPU-hour.

  T2 instances’ baseline performance and ability to burst are governed by CPU Credits. Each T2 instance receives CPU Credits continuously, the rate of which depends on the instance size. T2 instances accrue CPU Credits when they are idle, and use CPU credits when they are active. A CPU Credit provides the performance of a full CPU core for one minute.

  For example, a t2.small instance receives credits continuously at a rate of 12 CPU Credits per hour. This capability provides baseline performance equivalent to 20% of a CPU core (20% x 60 mins = 12 mins). If the instance does not use the credits it receives, they are stored in its CPU Credit balance up to a maximum of 288 CPU Credits. When the t2.small instance needs to burst to more than 20% of a core, it draws from its CPU Credit balance to handle this surge automatically.

  If the instance happens to run at an average 25% CPU utilization (5% above baseline) over a period of 24 hours after its CPU Credit balance is drawn to zero, it will be charged an additional 6 cents (5 cents/vCPU-hour x 1 vCPU x 5% x 24 hours).

See `How powerful are the burstable aws t2 instances <https://www.algotech.solutions/blog/engineering/how-powerful-are-the-burstable-aws-t2-instances/>`_ for an example of burstable t2 instance usage.

See `AWS EC2 T2 Instances Demystified: Don’t Learn The Hard Way <https://roberttisdale.com/aws-ec2-t2-instances-demystified-dont-learn-hard-way/>`_ for more discussion of T2 bursting. To allow unlimited bursting requires specifying ``--credit-specification CpuCredits=unlimited`` like ``aws ec2 run-instances ... --credit-specification CpuCredits=unlimited``.


SSD bursting
""""""""""""

From `New SSD-Backed Elastic Block Storage: Under the Hood - Performance Burst Details <https://aws.amazon.com/blogs/aws/new-ssd-backed-elastic-block-storage/>`_, the token bucket implementations works as follows:

* Token is I/O credit for 1 read or write.

* Token bucket for each general purpose SSD holding up to 5.4 million tokens.

* Add 3 tokens/GB/second.

* Tokens spent up to 3000/second/volume.

* Baseline performance is 3 IOPS/GB/second.

For a more detailed discussion see burst and credit discussions in `Amazon Elastic Compute Cloud Amazon EBS Volume Types <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html>`_ and the presentation `AWS - an introduction to bursting (GP2 - T2) <https://www.slideshare.net/rasmusekman/aws-an-introduction-to-bursting-gp2-t2>`_.
