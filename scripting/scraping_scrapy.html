

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta content="default-src 'none'; script-src 'self' https://cdnjs.cloudflare.com 'unsafe-inline'; connect-src 'self'; img-src 'self'; style-src 'self'; font-src 'self'; form-action 'self'; frame-ancestors 'none'; base-uri 'self'" http-equiv="Content-Security-Policy" />
<meta content="nosniff" http-equiv="X-Content-Type-Options" />
<meta content="deny" http-equiv="X-Frame-Options" />
<meta content="1; mode=block" http-equiv="X-XSS-Protection" />
<meta content="strict-origin" http-equiv="Referrer-Policy" />
<meta content="max-age=31536000; includeSubDomains" http-equiv="Strict-Transport-Security" />
<meta content="'*'" http-equiv="Access-Control-Allow-Origin" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>10.4. Scraping with Scrapy &mdash; South Bay WASP 1.0.3 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="South Bay WASP 1.0.3 documentation" href="../index.html"/>
        <link rel="up" title="10. Pentest scripting" href="../pentest_scripting.html"/>
        <link rel="next" title="10.5. Internet data" href="internet_data.html"/>
        <link rel="prev" title="10.3. Scraping with Beautiful Soup" href="scraping_soup.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> South Bay WASP
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../pentest_intro.html">1. South Bay WASP Meetup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pentest_kali.html">2. Kali Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pentest_challenges.html">3. Pentest Challenges</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pentest_encryption.html">4. Encryption</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pentest_html.html">5. HTML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pentest_network_tools.html">6. Pentest Network Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pentest_recon.html">7. Pentest Reconnaisance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pentest_study.html">8. Pentest Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pentest_buffer_overflow.html">9. Pentest Buffer Overflow</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../pentest_scripting.html">10. Pentest scripting</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="bash.html">10.1. <code class="docutils literal notranslate"><span class="pre">bash</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="python.html">10.2. Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="scraping_soup.html">10.3. Scraping with Beautiful Soup</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">10.4. Scraping with Scrapy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#learning-scrapy">10.4.1. Learning Scrapy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#simple-scrapy-examples">10.4.2. Simple Scrapy examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#setting-up-scrapy">10.4.2.1. Setting up Scrapy</a></li>
<li class="toctree-l4"><a class="reference internal" href="#scrapy-without-a-project">10.4.2.2. Scrapy without a project</a></li>
<li class="toctree-l4"><a class="reference internal" href="#scrapy-shell">10.4.2.3. Scrapy shell</a></li>
<li class="toctree-l4"><a class="reference internal" href="#scrapy-with-a-project">10.4.2.4. Scrapy with a project</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#javascript-handling">10.4.3. JavaScript handling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="internet_data.html">10.5. Internet data</a></li>
<li class="toctree-l2"><a class="reference internal" href="networking.html">10.6. Networking</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../pentest_presentations.html">11. Pentest Presentations</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">South Bay WASP</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../pentest_scripting.html">10. Pentest scripting</a> &raquo;</li>
        
      <li>10.4. Scraping with Scrapy</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/scripting/scraping_scrapy.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="scraping-with-scrapy">
<h1>10.4. Scraping with <a class="reference external" href="https://scrapy.org/">Scrapy</a><a class="headerlink" href="#scraping-with-scrapy" title="Permalink to this headline">¶</a></h1>
<div class="section" id="learning-scrapy">
<h2>10.4.1. Learning <a class="reference external" href="https://scrapy.org/">Scrapy</a><a class="headerlink" href="#learning-scrapy" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference external" href="https://scrapy.org/">Scrapy</a> website introduces the concept that Scrapy can be run from:</p>
<ul>
<li><p class="first">end-user PCs</p>
</li>
<li><p class="first">a self-hosted Scrapyd server: see <a class="reference external" href="http://scrapyd.readthedocs.io/">Scrapyd Documentation</a> and <a class="reference external" href="https://github.com/scrapy/scrapyd">Scrapyd GitHub</a></p>
</li>
<li><p class="first">the <a class="reference external" href="https://scrapinghub.com/scrapy-cloud/">Scrapycloud</a></p>
<p>There is a free level (currently 1 concurrent crawl job limited to 24 hours with 7 day data retention).</p>
<p>Scrapy documentation asserts “Scrapy Cloud is compatible with Scrapyd and one can switch between them as needed”.</p>
</li>
</ul>
<p>The very first page of <a class="reference external" href="https://doc.scrapy.org/en/latest/">Scrapy documentation</a> contains a good outline of the concepts needed to understand Scrapy.</p>
<p>Examples may be found at <a class="reference external" href="https://scrapy.org/resources/">Curated Scrapy Resources</a> and <a class="reference external" href="https://doc.scrapy.org/en/latest/intro/examples.html">Scrapy Examples</a>.</p>
</div>
<div class="section" id="simple-scrapy-examples">
<h2>10.4.2. Simple Scrapy examples<a class="headerlink" href="#simple-scrapy-examples" title="Permalink to this headline">¶</a></h2>
<div class="section" id="setting-up-scrapy">
<h3>10.4.2.1. Setting up Scrapy<a class="headerlink" href="#setting-up-scrapy" title="Permalink to this headline">¶</a></h3>
<p>On Debian 9 the version of Scrapy from the packages was 1.0.3-2 while the latest is 1.4. Trying to run the Scrapy documentation examples failed due to the old version, so the following were required to setup the latest Scrapy:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Update to latest pip, setuptools, wheel.</span>
sudo apt install build-essential libssl-dev libffi-dev python-dev -y
pip install -U pip setuptools wheel

<span class="c1"># Create a python3 environement with Scrapy installed</span>
python3 -m venv ~/python3
<span class="nb">cd</span> ~/python3
<span class="nb">source</span> bin/activate
pip install -U Scrapy
</pre></div>
</div>
</div>
<div class="section" id="scrapy-without-a-project">
<h3>10.4.2.2. Scrapy without a project<a class="headerlink" href="#scrapy-without-a-project" title="Permalink to this headline">¶</a></h3>
<p>Start with the <a class="reference external" href="https://doc.scrapy.org/en/latest/intro/overview.html">Scrapy at a glance</a>, which illustrates a Scrapy run without a project. Here, the website <a class="reference external" href="http://quotes.toscrape.com/">http://quotes.toscrape.com/</a> is spidered to obtain the quotes into a JSON or CSV output. Be sure to view the web page source to make sense of the <cite>quote.css(‘span.text::text’)</cite>, <cite>quote.xpath(‘span/small/text()’)</cite>, and <cite>response.css(‘li.next a::attr(“href”)’)</cite> code segments.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Environment setup above</span>
<span class="nb">cd</span> ~/python3
<span class="c1"># source bin/activate</span>
mkdir -p scrapy
<span class="nb">cd</span> scrapy

<span class="c1"># Create quotes_spider.py</span>
cat &gt; quotes_spider.py <span class="s">&lt;&lt;&#39;EOF&#39;</span>
<span class="s">import scrapy</span>


<span class="s">class QuotesSpider(scrapy.Spider):</span>
<span class="s">    name = &quot;quotes&quot;</span>
<span class="s">    start_urls = [</span>
<span class="s">        &#39;http://quotes.toscrape.com/tag/humor/&#39;,</span>
<span class="s">    ]</span>

<span class="s">    def parse(self, response):</span>
<span class="s">        for quote in response.css(&#39;div.quote&#39;):</span>
<span class="s">            yield {</span>
<span class="s">                &#39;text&#39;: quote.css(&#39;span.text::text&#39;).extract_first(),</span>
<span class="s">                &#39;author&#39;: quote.xpath(&#39;span/small/text()&#39;).extract_first(),</span>
<span class="s">            }</span>

<span class="s">        next_page = response.css(&#39;li.next a::attr(&quot;href&quot;)&#39;).extract_first()</span>
<span class="s">        if next_page is not None:</span>
<span class="s">            yield response.follow(next_page, self.parse)</span>
<span class="s">EOF</span>

<span class="c1"># Run it with JSON output.</span>
scrapy runspider quotes_spider.py -o quotes.json

<span class="c1"># Change to CSV output.</span>
scrapy runspider quotes_spider.py -o quotes.csv

<span class="c1"># When done, deactivate venv.</span>
<span class="c1"># deactivate</span>
</pre></div>
</div>
</div>
<div class="section" id="scrapy-shell">
<h3>10.4.2.3. Scrapy shell<a class="headerlink" href="#scrapy-shell" title="Permalink to this headline">¶</a></h3>
<p>The Scrapy shell can be used to help create or debug the above Scrapy spider:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>scrapy shell http://quotes.toscrape.com/tag/humor/
response.css<span class="o">(</span><span class="s1">&#39;div.quote&#39;</span><span class="o">)</span>
<span class="nv">quote</span> <span class="o">=</span> response.css<span class="o">(</span><span class="s1">&#39;div.quote&#39;</span><span class="o">)[</span><span class="m">0</span><span class="o">]</span>
quote.css<span class="o">(</span><span class="s1">&#39;span.text&#39;</span><span class="o">)</span>
quote.css<span class="o">(</span><span class="s1">&#39;span.text::text&#39;</span><span class="o">)</span>
quote.css<span class="o">(</span><span class="s1">&#39;span.text::text&#39;</span><span class="o">)</span>.extract_first<span class="o">()</span>
response.css<span class="o">(</span><span class="s1">&#39;li.next&#39;</span><span class="o">)</span>
response.css<span class="o">(</span><span class="s1">&#39;li.next a&#39;</span><span class="o">)</span>
response.css<span class="o">(</span><span class="s1">&#39;li.next a::attr(&quot;href&quot;)&#39;</span><span class="o">)</span>
response.css<span class="o">(</span><span class="s1">&#39;li.next a::attr(&quot;href&quot;)&#39;</span><span class="o">)</span>.extract_first<span class="o">()</span>
exit<span class="o">()</span>

<span class="c1"># Get rid of venv</span>
deactivate
<span class="nb">cd</span>
rm -rf ~/python3
</pre></div>
</div>
</div>
<div class="section" id="scrapy-with-a-project">
<h3>10.4.2.4. Scrapy with a project<a class="headerlink" href="#scrapy-with-a-project" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference external" href="https://doc.scrapy.org/en/latest/intro/tutorial.html">Scrapy tutorial</a> creates a project using the QuotesSpider above and goes into more detail explaining the CSS selector <cite>response.css(…)</cite> and the XPath expression <cite>quote.xpath(…).extract_first()</cite>.</p>
</div>
</div>
<div class="section" id="javascript-handling">
<h2>10.4.3. JavaScript handling<a class="headerlink" href="#javascript-handling" title="Permalink to this headline">¶</a></h2>
<p>From <a class="reference external" href="https://blog.scrapinghub.com/2015/03/02/handling-javascript-in-scrapy-with-splash/">Handling JavaScript in Scrapy with Splash</a>:</p>
<blockquote>
<div>A common roadblock when developing spiders is dealing with sites that use a heavy amount of JavaScript. Many modern websites run entirely on JavaScript, and require scripts to be run in order for the page to render properly. In many cases, pages also present modals and other dialogues that need to be interacted with to show the full page. In this post we’re going to show you how you can use Splash to handle JavaScript in your Scrapy projects.</div></blockquote>
<p>For more information consult:</p>
<ul class="simple">
<li><a class="reference external" href="https://github.com/scrapinghub/splash">scrapinghub/splash</a> is the JavaScript rendering service code.</li>
<li><a class="reference external" href="https://splash.readthedocs.io/">Splash - A javascript rendering service</a> is the documentation for the Splash server.</li>
<li><a class="reference external" href="https://github.com/scrapy-plugins/scrapy-splash">scrapy-plugins/scrapy-splash</a> is the Scrapy plugin that allows Scrapy to interface with the Splash service.</li>
</ul>
<p>Needless to say, scraping JavaScript sites can get to be complex.
with a project</p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="internet_data.html" class="btn btn-neutral float-right" title="10.5. Internet data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="scraping_soup.html" class="btn btn-neutral" title="10.3. Scraping with Beautiful Soup" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, bitbender.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.0.3',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>